#!/usr/bin/env python3
import rospy
from sensor_msgs.msg import Image

import numpy as np
import os
import torch
import time

import cv2
from cv_bridge import CvBridge, CvBridgeError

import packnet_sfm

from packnet_sfm.models.model_wrapper import ModelWrapper
from packnet_sfm.datasets.augmentations import resize_image, to_tensor
from packnet_sfm.utils.horovod import hvd_init, rank, world_size, print0
from packnet_sfm.utils.image import load_image
from packnet_sfm.utils.config import parse_test_file
from packnet_sfm.utils.load import set_debug
from packnet_sfm.utils.depth import write_depth, inv2depth, viz_inv_depth
from packnet_sfm.utils.logging import pcolor

from packnet_sfm.utils.types import is_seq, is_tensor

class DepthInference:
    def __init__(self):
        self.bridge = CvBridge()

        self.model_wrapper = None
        self.network_input_shape = None
        self.input_image_shape = None
        self.set_model_wrapper()

        rospy.Subscriber("/video/image_raw", Image, self.cb_image, queue_size=1)
        rospy.spin()


    def set_model_wrapper(self):

        config, state_dict = parse_test_file("/home/jedsadakorn/packnet_ws/src/packnet_sfm/models/PackNet01_HR_velsup_CStoK.ckpt")
        
        self.set_network_input_shape(config)

        # Initialize model wrapper from checkpoint arguments
        self.model_wrapper = ModelWrapper(config, load_datasets=False)
        # Restore monodepth_model state
        self.model_wrapper.load_state_dict(state_dict)

        if torch.cuda.is_available():
            self.model_wrapper = self.model_wrapper.to('cuda:{}'.format(rank()), dtype=None)
        
        # Set to eval mode
        self.model_wrapper.eval()
    

    def set_network_input_shape(self, config):
        self.network_input_shape = config.datasets.augmentation.image_shape


    def inv2depth(self, inv_depth):
        """
        Invert an inverse depth map to produce a depth map

        Parameters
        ----------
        inv_depth : torch.Tensor or list of torch.Tensor [B,1,H,W]
            Inverse depth map

        Returns
        -------
        depth : torch.Tensor or list of torch.Tensor [B,1,H,W]
            Depth map
        """
        if is_seq(inv_depth):
            return [inv2depth(item) for item in inv_depth]
        else:
            # return 1. / inv_depth.clamp(min=1e-6, max=80)
            return 1. / inv_depth


    def write_depth(self, depth):
        """
        Write a depth map to file, and optionally its corresponding intrinsics.

        This code is modified to export compatible-format depth image to openVSLAM

        Parameters
        ----------
        depth : np.array [H,W]
            Depth map
        """
        # If depth is a tensor
        if is_tensor(depth):
            depth = depth.detach().squeeze().cpu()  # This is the bottle neck of 300mss
            depth = depth.numpy()
            depth = cv2.resize(src=depth, dsize=(self.input_image_shape[1], self.input_image_shape[0]))
            depth = np.clip(depth, 0, 80)
            depth = np.uint16(depth * 256)

            # cv2.imwrite("/home/jedsadakorn/packnet_ws/src/packnet_sfm/inferences/test.png", depth)

        return depth
            



    def cb_image(self, data):
        rospy.loginfo("Image recieved")

        try:
            image = self.bridge.imgmsg_to_cv2(data, "rgb8")
        except CvBridgeError as e:
            print(e)

        self.input_image_shape = image.shape

        image = cv2.resize(image, (self.network_input_shape[1], self.network_input_shape[0]))
        image = to_tensor(image).unsqueeze(0)

        if torch.cuda.is_available():
            image = image.to('cuda:{}'.format(rank()), dtype=None)
        
        pred_inv_depth = self.model_wrapper.depth(image)[0]
        # depth = self.write_depth(depth=self.inv2depth(pred_inv_depth))


    

if __name__ == "__main__":
    rospy.init_node('packnet_sfm_node')
    
    depth_inference_node = DepthInference()
