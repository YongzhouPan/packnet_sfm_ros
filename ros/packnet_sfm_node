#!/usr/bin/env python3
import rospy
from sensor_msgs.msg import Image

import numpy as np
import os
import torch
import time

import cv2
from cv_bridge import CvBridge, CvBridgeError

import packnet_sfm

from packnet_sfm.models.model_wrapper import ModelWrapper
from packnet_sfm.datasets.augmentations import resize_image, to_tensor
from packnet_sfm.utils.horovod import hvd_init, rank, world_size, print0
from packnet_sfm.utils.image import load_image
from packnet_sfm.utils.config import parse_test_file
from packnet_sfm.utils.load import set_debug
from packnet_sfm.utils.depth import write_depth, inv2depth, viz_inv_depth
from packnet_sfm.utils.logging import pcolor

from packnet_sfm.utils.types import is_seq, is_tensor

class DepthInference:
    def __init__(self):
        self.bridge = CvBridge()

        self.model_wrapper = None
        self.network_input_shape = None
        self.rgb_img_msg = None
        self.depth_img_msg = None
        self.set_model_wrapper()

        # Communication
        self.pub_rgb_image = rospy.Publisher('/rgb_image', Image, queue_size=None)
        self.pub_depth_image = rospy.Publisher('/depth_image', Image, queue_size=None)

        # queue_size=None to process only the last message
        rospy.Subscriber("/video/image_raw", Image, self.cb_image, queue_size=None)

        rate = rospy.Rate(10) # 10hz
        while not rospy.is_shutdown():
            if self.rgb_img_msg is None:
                continue

            self.process(self.rgb_img_msg)
            rate.sleep()

        # rospy.spin()


    def set_model_wrapper(self):

        config, state_dict = parse_test_file("/home/jedsadakorn/packnet_ws/src/packnet_sfm/models/PackNet01_HR_velsup_CStoK.ckpt")
        
        self.set_network_input_shape(config)

        # Initialize model wrapper from checkpoint arguments
        self.model_wrapper = ModelWrapper(config, load_datasets=False)
        # Restore monodepth_model state
        self.model_wrapper.load_state_dict(state_dict)

        if torch.cuda.is_available():
            self.model_wrapper = self.model_wrapper.to('cuda:{}'.format(rank()), dtype=None)
        
        # Set to eval mode
        self.model_wrapper.eval()
    

    def set_network_input_shape(self, config):
        self.network_input_shape = config.datasets.augmentation.image_shape

    def process(self, rgb_img_msg):

        try:
            rgb_image = self.bridge.imgmsg_to_cv2(rgb_img_msg, "rgb8")
        except CvBridgeError as e:
            print(e)
            
        rgb_image = cv2.resize(rgb_image, (self.network_input_shape[1], self.network_input_shape[0]))
        rgb_image = to_tensor(rgb_image).unsqueeze(0)

        if torch.cuda.is_available():
            rgb_image = rgb_image.to('cuda:{}'.format(rank()), dtype=None)
        
        pred_inv_depth = self.model_wrapper.depth(rgb_image)[0]
        depth_img = self.write_depth(self.inv2depth(pred_inv_depth))
        depth_img_msg = self.bridge.cv2_to_imgmsg(depth_img, encoding="mono16")

        self.pub_rgb_image.publish(rgb_img_msg)
        self.pub_depth_image.publish(depth_img_msg)


    def inv2depth(self, inv_depth):
        """
        Invert an inverse depth map to produce a depth map

        Parameters
        ----------
        inv_depth : torch.Tensor or list of torch.Tensor [B,1,H,W]
            Inverse depth map

        Returns
        -------
        depth : torch.Tensor or list of torch.Tensor [B,1,H,W]
            Depth map
        """
        if is_seq(inv_depth):
            return [inv2depth(item) for item in inv_depth]
        else:
            # return 1. / inv_depth.clamp(min=1e-6, max=80)
            return 1. / inv_depth


    def write_depth(self, depth):
        """
        Write a depth map to file, and optionally its corresponding intrinsics.

        This code is modified to export compatible-format depth image to openVSLAM

        Parameters
        ----------
        depth : np.array [H,W]
            Depth map
        """
        # If depth is a tensor
        if is_tensor(depth):
            depth = depth.detach().squeeze().cpu()  # This is the bottle neck of 300mss
            depth = depth.numpy()
            depth = cv2.resize(src=depth, dsize=(self.input_image_shape[1], self.input_image_shape[0]))
            depth = np.clip(depth, 0, 80)
            depth = np.uint16(depth * 256)

            # cv2.imwrite("/home/jedsadakorn/packnet_ws/src/packnet_sfm/inferences/test.png", depth)

        return depth

    def cb_image(self, data):
        rospy.loginfo(data.header.seq)
        self.rgb_img_msg = data
        self.input_image_shape = (data.height, data.width)
        print(self.input_image_shape)


    

if __name__ == "__main__":
    rospy.init_node('packnet_sfm_node')
    
    depth_inference_node = DepthInference()
